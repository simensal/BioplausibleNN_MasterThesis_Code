{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network\n",
    "The purpose of the following notebook is to provide a simple implementation to get hands on experience, and thus hopefully also a deeper understanding of the backwards error propagation approach to neural network. The task for the network is to classify iris set of data from [UCI](https://archive.ics.uci.edu/ml/datasets/Iris), and will thereby be a form of supervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up the artificial network class [WIP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_function(x):\n",
    "    \"\"\"Calculates the activation of a node give an input\n",
    "\n",
    "    Args:\n",
    "        x (integer: Scalar) :  Number representing the sum of the input to the give node\n",
    "    \"\"\"\n",
    "    return (1 + np.e**-x)**-1\n",
    "\n",
    "activation = np.vectorize(activation_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN:\n",
    "    def __init__(self, features, hidden_layers, outputs):\n",
    "        \"\"\"\n",
    "        Takes as input\n",
    "            hidden_layers : 1d array with number of neurons to include in each of the hidden layers\n",
    "            features : int representing the number of features of the data set - corresponds to the first (input) layer\n",
    "            outputs : int representing the number of possible outputs - and thereby number of nodes in the final (output) layer\n",
    "        \"\"\"\n",
    "        \n",
    "        # Meta data\n",
    "        self.num_layers = len(hidden_layers) + 2\n",
    "        self.num_outputs = outputs\n",
    "        self.num_features = features\n",
    "        \n",
    "        combined_layers  = np.array([features] + hidden_layers + [outputs])\n",
    "\n",
    "        # Setting up the layers\n",
    "        self.layers = []\n",
    "        for num in combined_layers:\n",
    "            self.layers.append([0 for _ in range(num)])\n",
    "\n",
    "        # Setting up weights\n",
    "        self.weights = []\n",
    "        for i in range(len(combined_layers)-1):\n",
    "            self.weights.append(np.random.rand(combined_layers[i], combined_layers[i+1]))\n",
    "    \n",
    "    def forward_pass(self, sample): \n",
    "        \"\"\"Fixes the neural network to a sample and generates the prediction at the output layer\n",
    "\n",
    "        Args:\n",
    "            sample (ndarray): Array of floats which represents the value of the input sample\n",
    "        \"\"\"\n",
    "        self.layers[0] = sample\n",
    "\n",
    "        # Iterate through each layer and calculate activation based on \n",
    "        for i in range(1, self.num_layers):\n",
    "            # Fetch the activation and weight of the previous layers\n",
    "            prev_activation = self.layers[i-1]\n",
    "            weights = self.weights[i-1]\n",
    "\n",
    "            # Calculate inputs of the current nodes based on activation of previous and weights between them\n",
    "            inputs = np.sum(weights * prev_activation[:, np.newaxis], axis = 0)\n",
    "\n",
    "            # Update current layer with activation of inputs\n",
    "            self.layers[i] = activation(inputs)\n",
    "\n",
    "    def predict(self, sample):\n",
    "        \"\"\"Predicts the label of a sample x\n",
    "\n",
    "        Args:\n",
    "            sample (ndarray): Array of integers which represents the first input layer of the network\n",
    "\n",
    "        Returns:\n",
    "            ndarray: Array of floats which represent the confidences of the classification for each category of the output\n",
    "        \"\"\"\n",
    "        self.forward_pass(sample)\n",
    "        return self.layers[-1]\n",
    "\n",
    "    def backprops_error(self, prediction, solution): \n",
    "        \"\"\"Compares a prediction to a solution and calculates the error between the layer and the expected values\n",
    "\n",
    "        Args:\n",
    "            prediction (ndarray): Prediction, output of the network for some sample x\n",
    "            solution (ndarray): The solution to the sample fetched from the dataset\n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data\n",
    "The data is loaded from `./data/iris.data` and utilizes `pandas` to preprocess it. This includes splitting the attributes and the labels, and converting the categorical label to integers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading from file\n",
    "df = pd.read_csv('./data/iris.data', names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'label'])\n",
    "y = df['label']\n",
    "x = df.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting labels from string to integers representing categories\n",
    "uniques = y.unique()\n",
    "label_map = {i: uniques[i] for i in range(len(uniques))}\n",
    "y.replace(uniques, [i for i in range(len(uniques))], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up network and making predictions [WIP]\n",
    "With the data loaded, the model is ready to be set up and make predictions based on the provided samples from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up network based on metadata\n",
    "model_hidden_layers = [10, 6]\n",
    "\n",
    "ann = ANN(len(x.columns), model_hidden_layers, len(uniques))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating arrays with solutions for easier error calculation\n",
    "solutions = []\n",
    "\n",
    "for _, solution in y.items():\n",
    "    \n",
    "    solutions.append([1 if i == solution else 0 for i in range(len(uniques))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.13926147 -0.96625076 -0.93710438]\n",
      "[ 0.13931469 -0.96622891 -0.93707086]\n",
      "[ 0.13931918 -0.96622727 -0.93706847]\n",
      "[ 0.13930458 -0.96623295 -0.93707686]\n",
      "[ 0.13925705 -0.96625258 -0.93710717]\n",
      "[ 0.1391824  -0.96628267 -0.93715312]\n",
      "[ 0.13927957 -0.96624326 -0.93709278]\n",
      "[ 0.13926096 -0.96625083 -0.93710436]\n",
      "[ 0.13935215 -0.96621357 -0.9370473 ]\n",
      "[ 0.13930177 -0.9662342  -0.93707886]\n",
      "[ 0.13922602 -0.96626515 -0.9371264 ]\n",
      "[ 0.13925672 -0.96625246 -0.93710671]\n",
      "[ 0.13933177 -0.96622205 -0.93706039]\n",
      "[ 0.13941795 -0.96618734 -0.93700776]\n",
      "[ 0.13922758 -0.96626488 -0.93712634]\n",
      "[ 0.1391663  -0.96628946 -0.9371638 ]\n",
      "[ 0.13921733 -0.96626875 -0.93713208]\n",
      "[ 0.13925209 -0.96625449 -0.93711007]\n",
      "[ 0.13918739 -0.96628068 -0.9371501 ]\n",
      "[ 0.13921994 -0.96626756 -0.93713005]\n",
      "[ 0.13922612 -0.96626485 -0.93712571]\n",
      "[ 0.13921886 -0.96626791 -0.93713054]\n",
      "[ 0.13933117 -0.96622291 -0.93706221]\n",
      "[ 0.13921917 -0.96626744 -0.93712956]\n",
      "[ 0.13922557 -0.96626491 -0.93712554]\n",
      "[ 0.13928248 -0.96624183 -0.93709038]\n",
      "[ 0.13923253 -0.96626217 -0.93712159]\n",
      "[ 0.13924628 -0.96625684 -0.93711361]\n",
      "[ 0.1392661  -0.96624885 -0.93710146]\n",
      "[ 0.13927745 -0.96624394 -0.93709361]\n",
      "[ 0.13928193 -0.96624208 -0.93709076]\n",
      "[ 0.1392307  -0.96626301 -0.93712304]\n",
      "[ 0.13921342 -0.96627043 -0.93713456]\n",
      "[ 0.13920176 -0.96627521 -0.93714198]\n",
      "[ 0.13930177 -0.9662342  -0.93707886]\n",
      "[ 0.13932073 -0.96622677 -0.93706792]\n",
      "[ 0.13926069 -0.9662512  -0.93710523]\n",
      "[ 0.13930177 -0.9662342  -0.93707886]\n",
      "[ 0.13935753 -0.96621156 -0.93704438]\n",
      "[ 0.13925738 -0.96625229 -0.93710661]\n",
      "[ 0.13926778 -0.9662482  -0.93710054]\n",
      "[ 0.13942787 -0.96618234 -0.93699974]\n",
      "[ 0.13933508 -0.96622079 -0.9370585 ]\n",
      "[ 0.13921102 -0.96627084 -0.93713486]\n",
      "[ 0.13917988 -0.96628354 -0.93715428]\n",
      "[ 0.13930778 -0.96623162 -0.93707496]\n",
      "[ 0.13921793 -0.96626837 -0.93713123]\n",
      "[ 0.13930913 -0.96623124 -0.93707439]\n",
      "[ 0.13922885 -0.96626399 -0.93712461]\n",
      "[ 0.13928207 -0.96624231 -0.93709141]\n",
      "[-0.86092581  0.03367376 -0.93721982]\n",
      "[-0.86092115  0.03367571 -0.93721672]\n",
      "[-0.8609264   0.03367352 -0.93722016]\n",
      "[-0.86088126  0.03369249 -0.93719006]\n",
      "[-0.86091562  0.03367808 -0.93721288]\n",
      "[-0.86090604  0.03368208 -0.93720655]\n",
      "[-0.86092517  0.03367402 -0.9372194 ]\n",
      "[-0.86084711  0.03370651 -0.93716838]\n",
      "[-0.86091633  0.03367776 -0.93721341]\n",
      "[-0.86088904  0.03368916 -0.93719543]\n",
      "[-0.86083879  0.03371013 -0.9371625 ]\n",
      "[-0.86091001  0.03368039 -0.93720929]\n",
      "[-0.86087883  0.03369349 -0.93718848]\n",
      "[-0.86091512  0.03367828 -0.93721258]\n",
      "[-0.86089125  0.03368817 -0.93719712]\n",
      "[-0.86091914  0.03367656 -0.93721538]\n",
      "[-0.86091177  0.03367966 -0.93721041]\n",
      "[-0.86089349  0.03368729 -0.93719837]\n",
      "[-0.86089862  0.03368529 -0.93720132]\n",
      "[-0.86088277  0.03369179 -0.93719127]\n",
      "[-0.86092376  0.03367463 -0.93721841]\n",
      "[-0.86090149  0.03368396 -0.93720366]\n",
      "[-0.860912    0.03367964 -0.93721031]\n",
      "[-0.86091109  0.03367997 -0.93720988]\n",
      "[-0.86091094  0.03368001 -0.93720988]\n",
      "[-0.86091666  0.03367761 -0.93721369]\n",
      "[-0.86091898  0.03367667 -0.93721511]\n",
      "[-0.86092614  0.03367365 -0.93721994]\n",
      "[-0.86091284  0.03367923 -0.93721107]\n",
      "[-0.86087496  0.03369495 -0.93718645]\n",
      "[-0.86087577  0.03369472 -0.93718666]\n",
      "[-0.8608709   0.03369671 -0.93718357]\n",
      "[-0.86089263  0.03368765 -0.93719782]\n",
      "[-0.8609171   0.03367748 -0.93721377]\n",
      "[-0.86091009  0.03368036 -0.9372093 ]\n",
      "[-0.860923    0.03367492 -0.937218  ]\n",
      "[-0.86092335  0.0336748  -0.93721813]\n",
      "[-0.86089783  0.03368559 -0.93720089]\n",
      "[-0.8609034   0.03368313 -0.93720498]\n",
      "[-0.86088732  0.03368992 -0.93719417]\n",
      "[-0.86089627  0.03368618 -0.93720003]\n",
      "[-0.86091582  0.03367797 -0.93721309]\n",
      "[-0.86089193  0.03368797 -0.93719727]\n",
      "[-0.86084477  0.03370751 -0.93716679]\n",
      "[-0.86089779  0.03368553 -0.93720111]\n",
      "[-0.86090467  0.0336826  -0.93720581]\n",
      "[-0.86090365  0.03368305 -0.93720507]\n",
      "[-0.86090944  0.03368064 -0.93720888]\n",
      "[-0.86084693  0.03370652 -0.93716854]\n",
      "[-0.86089953  0.03368478 -0.93720233]\n",
      "[-0.86093998 -0.96633221  0.06277067]\n",
      "[-0.8609183  -0.96632301  0.06278544]\n",
      "[-0.86093702 -0.96633094  0.06277273]\n",
      "[-0.86092845 -0.96632731  0.06277856]\n",
      "[-0.86093451 -0.96632988  0.06277444]\n",
      "[-0.86094266 -0.96633333  0.06276887]\n",
      "[-0.86089581 -0.96631358  0.06280039]\n",
      "[-0.86093768 -0.96633122  0.0627723 ]\n",
      "[-0.86092602 -0.96632625  0.06278031]\n",
      "[-0.86094625 -0.96633488  0.06276635]\n",
      "[-0.86093094 -0.96632838  0.0627768 ]\n",
      "[-0.86092389 -0.96632537  0.06278168]\n",
      "[-0.86093312 -0.96632929  0.06277537]\n",
      "[-0.86091352 -0.96632098  0.06278871]\n",
      "[-0.86092383 -0.96632535  0.0627817 ]\n",
      "[-0.86093371 -0.96632955  0.06277494]\n",
      "[-0.86093009 -0.96632801  0.06277742]\n",
      "[-0.8609507  -0.96633678  0.06276327]\n",
      "[-0.86094109 -0.96633266  0.06276999]\n",
      "[-0.86090446 -0.96631714  0.06279487]\n",
      "[-0.86093832 -0.9663315   0.06277181]\n",
      "[-0.86091748 -0.96632268  0.06278594]\n",
      "[-0.86094102 -0.96633263  0.06277002]\n",
      "[-0.86091853 -0.96632312  0.06278526]\n",
      "[-0.86093785 -0.96633131  0.06277211]\n",
      "[-0.86093898 -0.96633178  0.06277136]\n",
      "[-0.86091864 -0.96632317  0.06278515]\n",
      "[-0.8609226  -0.96632486  0.06278244]\n",
      "[-0.8609293  -0.96632766  0.06277802]\n",
      "[-0.86093429 -0.96632979  0.06277458]\n",
      "[-0.86093603 -0.96633051  0.06277343]\n",
      "[-0.86094942 -0.96633623  0.06276415]\n",
      "[-0.86092988 -0.9663279   0.06277762]\n",
      "[-0.86092004 -0.96632377  0.06278422]\n",
      "[-0.86091954 -0.96632354  0.06278463]\n",
      "[-0.86094106 -0.96633266  0.06276996]\n",
      "[-0.8609383 -0.9663315  0.0627718]\n",
      "[-0.86093104 -0.96632842  0.06277676]\n",
      "[-0.86092097 -0.96632417  0.06278353]\n",
      "[-0.86093414 -0.96632972  0.06277467]\n",
      "[-0.86093621 -0.9663306   0.06277327]\n",
      "[-0.86093299 -0.96632924  0.06277543]\n",
      "[-0.8609183  -0.96632301  0.06278544]\n",
      "[-0.86093918 -0.96633186  0.06277123]\n",
      "[-0.86093964 -0.96633206  0.0627709 ]\n",
      "[-0.86093154 -0.96632862  0.06277644]\n",
      "[-0.86091673 -0.96632233  0.06278655]\n",
      "[-0.86092887 -0.96632749  0.06277825]\n",
      "[-0.86093613 -0.96633058  0.06277326]\n",
      "[-0.86092338 -0.96632519  0.06278193]\n"
     ]
    }
   ],
   "source": [
    "# Making predictions for each sample and printing error terms\n",
    "predictions = []\n",
    "\n",
    "for idx, sample in x.iterrows():\n",
    "    pred = ann.predict(sample.to_numpy())\n",
    "\n",
    "    print(solutions[idx] - pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('lenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a2ccf82656375290734cff96e6fbdec1d491495344683b3c0e65ca34c044023"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
