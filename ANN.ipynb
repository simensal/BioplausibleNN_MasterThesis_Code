{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network\n",
    "\n",
    "The purpose of the following notebook is to provide a simple implementation to get hands on experience, and thus hopefully also a deeper understanding of the backwards error propagation approach to neural network. The task for the network is to classify iris set of data from [UCI](https://archive.ics.uci.edu/ml/datasets/Iris), and will thereby be a form of supervised learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up the artificial network class [WIP]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_function(x):\n",
    "    \"\"\"Calculates the activation of a node give an input\n",
    "\n",
    "    Args:\n",
    "        x (integer: Scalar) :  Number representing the sum of the input to the give node\n",
    "    \"\"\"\n",
    "    return (1 + np.e**-x)**-1\n",
    "\n",
    "\n",
    "def der_activation_function(x):\n",
    "\n",
    "    return (np.e**-x)/((1+np.e**-x)**2)\n",
    "\n",
    "\n",
    "activation = np.vectorize(activation_function)\n",
    "der_activation = np.vectorize(der_activation_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(prediction, solution):\n",
    "    \"\"\"Calculates the cost of a single sample\n",
    "\n",
    "    Args:\n",
    "        prediction (ndarray) : Output from the learner\n",
    "        soution (ndarray) : Solution for the sample\n",
    "\n",
    "    Returns: \n",
    "        float : Cost of the single training sample\n",
    "    \"\"\"\n",
    "    return np.sum((prediction - solution)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN:\n",
    "    def __init__(self, features, hidden_layers, outputs, learning_rate=0.01):\n",
    "        \"\"\"\n",
    "        Takes as input\n",
    "            hidden_layers : 1d array with number of neurons to include in each of the hidden layers\n",
    "            features : int representing the number of features of the data set - corresponds to the first (input) layer\n",
    "            outputs : int representing the number of possible outputs - and thereby number of nodes in the final (output) layer\n",
    "        \"\"\"\n",
    "\n",
    "        # Meta data\n",
    "        self.num_layers = len(hidden_layers) + 2\n",
    "        self.num_outputs = outputs\n",
    "        self.num_features = features\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        combined_layers = np.array([features] + hidden_layers + [outputs])\n",
    "\n",
    "        # Setting up the layers\n",
    "        self.layers = []\n",
    "        self.deltas = []\n",
    "        for num in combined_layers:\n",
    "            self.layers.append([0 for _ in range(num)])\n",
    "            self.deltas.append([0 for _ in range(num)])\n",
    "\n",
    "        # Setting up weights and layer inputs\n",
    "        self.layer_inputs = []\n",
    "        self.weights = []\n",
    "        #self.margins = []\n",
    "        for i in range(len(combined_layers)-1):\n",
    "            self.weights.append(np.random.rand(\n",
    "                combined_layers[i], combined_layers[i+1]))\n",
    "            #self.margins.append(np.zeros(np.shape((combined_layers[i], combined_layers[i+1]))))\n",
    "            self.layer_inputs.append([0 for _ in range(combined_layers[i])])\n",
    "\n",
    "    def forward_pass(self, sample):\n",
    "        \"\"\"Fixes the neural network to a sample and generates the prediction at the output layer\n",
    "\n",
    "        Args:\n",
    "            sample (ndarray): Array of floats which represents the value of the input sample\n",
    "        \"\"\"\n",
    "        self.layers[0] = sample\n",
    "\n",
    "        # Iterate through each layer and calculate activation based on\n",
    "        for i in range(1, self.num_layers):\n",
    "            # Fetch the activation and weight of the previous layers\n",
    "            prev_activation = self.layers[i-1]\n",
    "            weights = self.weights[i-1]\n",
    "\n",
    "            # Calculate inputs of the current nodes based on activation of previous and weights between them\n",
    "            self.layer_inputs[i-1] = np.dot(weights.T, prev_activation)\n",
    "\n",
    "            # Update current layer with activation of inputs\n",
    "            self.layers[i] = activation(self.layer_inputs[i-1])\n",
    "\n",
    "    def predict(self, sample):\n",
    "        \"\"\"Predicts the label of a sample x\n",
    "\n",
    "        Args:\n",
    "            sample (ndarray): Array of integers which represents the first input layer of the network\n",
    "\n",
    "        Returns:\n",
    "            ndarray: Array of floats which represent the confidences of the classification for each category of the output\n",
    "        \"\"\"\n",
    "        self.forward_pass(sample)\n",
    "        return self.layers[-1]\n",
    "\n",
    "    def backprops_error(self, solution):\n",
    "        \"\"\"Compares a prediction to a solution and calculates the error between the layer and the expected values\n",
    "        (Propagates the deltas down the network from the output)\n",
    "\n",
    "        Args:\n",
    "            prediction (ndarray): Prediction, output of the network for some sample x\n",
    "            solution (ndarray): The solution to the sample fetched from the dataset\n",
    "        \"\"\"\n",
    "        \n",
    "        # Calculate error of output layer\n",
    "        self.deltas[-1] = der_activation(self.layer_inputs[-1]) * (self.layers[-1] - solution)\n",
    "\n",
    "        # Iterate from outputlayer backwards and propagate error\n",
    "        for i in range(len(self.weights) - 1, 0, -1):\n",
    "            self.deltas[i] = der_activation(self.layer_inputs[i-1]) * np.dot(self.weights[i], self.deltas[i + 1])\n",
    "\n",
    "            #self.margins[i] = self.learning_rate * self.layers[i] * der_activation(self.layer_inputs[i]) * self.deltas[i + 1]\n",
    "\n",
    "    def update_network(self, solution):\n",
    "        \"\"\"Calculates the margins of weights for the network given a traning example, and updates the weights accordingly\n",
    "        \"\"\"\n",
    "        for i in range(len(self.weights)):\n",
    "            margins = -self.learning_rate * np.outer(self.layers[i], self.deltas[i + 1].T)\n",
    "            self.weights[i] = self.weights[i] + margins\n",
    "\n",
    "    def train_sample(self, sample, solution): \n",
    "        \"\"\"Trains the network on a single sample\n",
    "\n",
    "        Args:\n",
    "            sample (ndarray(4,)): Sample to make prediction on\n",
    "            solution (ndarray(3,)): Solution to the respective sample passed\n",
    "        \"\"\"\n",
    "        self.predict(sample)\n",
    "        self.backprops_error(solution)\n",
    "        self.update_network(solution)\n",
    "\n",
    "    def train(self, samples, solutions):\n",
    "        \"\"\"Trains the network on a set of samples and respective solutions\n",
    "\n",
    "        Args:\n",
    "            samples (ndarray(n,)): Set of samples for the network to make predictions on and train for\n",
    "            solutions (ndarray(n,)): Set of respective solutions to the samples\n",
    "        \"\"\"\n",
    "        assert len(samples) == len(solutions)\n",
    "\n",
    "        for sample, solution in zip(samples, solutions):\n",
    "            self.train_sample(sample, solution)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data\n",
    "\n",
    "The data is loaded from `./data/iris.data` and utilizes `pandas` to preprocess it. This includes splitting the attributes and the labels, and converting the categorical label to integers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading from file\n",
    "df = pd.read_csv('./data/iris.data',\n",
    "                 names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'label'])\n",
    "y = df['label']\n",
    "x = df.drop(['label'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting labels from string to integers representing categories\n",
    "uniques = y.unique()\n",
    "label_map = {i: uniques[i] for i in range(len(uniques))}\n",
    "y.replace(uniques, [i for i in range(len(uniques))], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up network and making predictions [WIP]\n",
    "\n",
    "With the data loaded, the model is ready to be set up and make predictions based on the provided samples from the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up network based on metadata\n",
    "model_hidden_layers = [10, 6]\n",
    "\n",
    "ann = ANN(len(x.columns), model_hidden_layers, len(uniques))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ann.layer_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.layer_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating arrays with solutions for easier error calculation\n",
    "solutions = []\n",
    "\n",
    "for _, solution in y.items():\n",
    "\n",
    "    solutions.append([1 if i == solution else 0 for i in range(len(uniques))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0]]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7968861450412419\n",
      "1.796169826677648\n",
      "1.7955173869642462\n",
      "1.7950056084818578\n",
      "1.794530482929604\n",
      "1.794230320389647\n",
      "1.7932536069758611\n",
      "1.7927500087857888\n",
      "1.7918517517870942\n",
      "1.791422628251286\n",
      "1.7910373108948034\n",
      "1.790318292898629\n",
      "1.789469711134056\n",
      "1.788485679270027\n",
      "1.788513605993717\n",
      "1.7881064196890233\n",
      "1.7872787990548342\n",
      "1.7865483292068447\n",
      "1.7861761829745446\n",
      "1.7853622873346544\n",
      "1.784762901654878\n",
      "1.7840766400819994\n",
      "1.7829212506386674\n",
      "1.7828192878485272\n",
      "1.7821269101308177\n",
      "1.781283606291617\n",
      "1.780746812647533\n",
      "1.780012228633805\n",
      "1.7792634598315562\n",
      "1.778555650810197\n",
      "1.7778710271333273\n",
      "1.7773519913242737\n",
      "1.7766459637387177\n",
      "1.775993987216535\n",
      "1.7750123560265523\n",
      "1.7741994937040162\n",
      "1.7737111607462455\n",
      "1.7728801045236229\n",
      "1.7719239614433586\n",
      "1.7715725271819334\n",
      "1.7707659313377255\n",
      "1.7696332672226935\n",
      "1.7690511576221353\n",
      "1.7688068465229256\n",
      "1.7681933843709086\n",
      "1.7669820704721846\n",
      "1.7665090673987103\n",
      "1.7654256787875795\n",
      "1.764957995087586\n",
      "1.764007490144024\n",
      "1.7813985467709919\n",
      "1.7806545215872327\n",
      "1.7799459223550576\n",
      "1.779066845347276\n",
      "1.7784345969601416\n",
      "1.777657105161972\n",
      "1.7769607917863302\n",
      "1.7759181568851408\n",
      "1.7754172882390133\n",
      "1.7745549789620991\n",
      "1.7736235416453532\n",
      "1.7730785817375674\n",
      "1.7722052407301887\n",
      "1.7715439660666528\n",
      "1.7706391011088671\n",
      "1.7699583589505976\n",
      "1.769145881462216\n",
      "1.7682680455808177\n",
      "1.7675063477611377\n",
      "1.766609055087963\n",
      "1.7659390563504136\n",
      "1.7650216856949204\n",
      "1.7642588735374949\n",
      "1.7634062413844107\n",
      "1.7625515818228719\n",
      "1.7617249146971692\n",
      "1.7608931317469265\n",
      "1.7600617466745192\n",
      "1.7591493971397152\n",
      "1.7581170800905341\n",
      "1.7572697650560125\n",
      "1.756366777078733\n",
      "1.7555557092197247\n",
      "1.754783068484115\n",
      "1.7538451175212642\n",
      "1.75297455311334\n",
      "1.7520739550567155\n",
      "1.7510867291294474\n",
      "1.7501595282053275\n",
      "1.7491899713818406\n",
      "1.7482970724385218\n",
      "1.747418231172991\n",
      "1.746382811692675\n",
      "1.745245059442911\n",
      "1.7445011270062536\n",
      "1.7435503621916821\n",
      "1.74258129754298\n",
      "1.7416256933084053\n",
      "1.7403713372100444\n",
      "1.7396175087974735\n",
      "1.9057189679378637\n",
      "1.9055204922833167\n",
      "1.9053690285616203\n",
      "1.9051851738313164\n",
      "1.9050190620002878\n",
      "1.904853441491886\n",
      "1.9046177623370981\n",
      "1.9044972997152791\n",
      "1.9043105617876412\n",
      "1.9041517270373889\n",
      "1.9039555935497368\n",
      "1.9037747489142065\n",
      "1.9036067976284\n",
      "1.903408107765448\n",
      "1.9032413086156794\n",
      "1.9030708763195308\n",
      "1.9028876765499796\n",
      "1.9027297064136708\n",
      "1.9025457166599111\n",
      "1.9023189265946572\n",
      "1.9021759921438472\n",
      "1.9019689398708008\n",
      "1.901818387645171\n",
      "1.9016046508551048\n",
      "1.901445482462503\n",
      "1.901263495812121\n",
      "1.9010528524575212\n",
      "1.9008725177369403\n",
      "1.9007025903835024\n",
      "1.9005195293264623\n",
      "1.9003389372389001\n",
      "1.9001627799902332\n",
      "1.899959681901049\n",
      "1.8997543507716634\n",
      "1.899570555212635\n",
      "1.8994079406749114\n",
      "1.8992143920158373\n",
      "1.8990160229114\n",
      "1.8988104077889005\n",
      "1.8986401621678264\n",
      "1.8984540100247775\n",
      "1.8982562100035365\n",
      "1.8980495630672267\n",
      "1.8978827236526243\n",
      "1.8976899957094915\n",
      "1.897486632948529\n",
      "1.8972766483328107\n",
      "1.8970947798703073\n",
      "1.8969086537964648\n",
      "1.8966970394893101\n"
     ]
    }
   ],
   "source": [
    "# Making predictions for each sample and printing error terms\n",
    "predictions = []\n",
    "\n",
    "for idx, sample in x.iterrows():\n",
    "    pred = ann.predict(sample.to_numpy())\n",
    "    ann.backprops_error(solutions[idx])\n",
    "    ann.update_network(solutions[idx])\n",
    "    print(cost_function(pred, solutions[idx]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('lenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a2ccf82656375290734cff96e6fbdec1d491495344683b3c0e65ca34c044023"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
